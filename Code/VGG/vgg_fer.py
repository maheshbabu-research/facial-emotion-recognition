# -*- coding: utf-8 -*-
"""vgg_fer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t8DLNmJ9b4_cssmKMc3-2dUFg-yHXDVo
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Lambda, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import VGG16
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np
from tensorflow.image import resize

class CustomVGG:
    def __init__(self, img_height, img_width, num_classes, learning_rate=0.0001):
        self.img_height = img_height
        self.img_width = img_width
        self.num_classes = num_classes
        self.learning_rate = learning_rate
        self.model = self.create_and_compile_model()

    def create_and_compile_model(self):
        model = Sequential()

        # Convert grayscale to RGB
        model.add(Lambda(lambda x: tf.image.grayscale_to_rgb(x),
                         input_shape=(self.img_height, self.img_width, 1),
                         output_shape=(self.img_height, self.img_width, 3)))

        # Load VGG16 model with ImageNet weights
        vgg = VGG16(weights='imagenet', include_top=False, input_shape=(self.img_height, self.img_width, 3))

        # Freeze all layers in VGG16
        for layer in vgg.layers:
            layer.trainable = False

        # Add VGG16 layers to the model
        model.add(vgg)

        # Flatten the output from VGG16
        model.add(Flatten())

        # Add fully connected layers
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.5))
        model.add(Dense(self.num_classes, activation='softmax'))

        # Compile the model
        model.compile(
            optimizer=Adam(learning_rate=self.learning_rate),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        return model

    def load_images(self, data_frame):
        images = []
        for index, row in data_frame.iterrows():
            pix = row['pixels']
            image = np.array(pix.split(), dtype='float32').reshape(48, 48)
            # Resize the image to 224x224
            image = resize(image, (self.img_height, self.img_width))
            images.append(image)
        return np.array(images)

    def preprocess_data(self, data_frame):
        # Load and preprocess the images
        X = self.load_images(data_frame)
        X = X.astype('float32') / 255.0  # Normalize pixel values
        y = data_frame['emotion'].values

        # Encode labels
        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)
        y_encoded = tf.keras.utils.to_categorical(y_encoded, num_classes=self.num_classes)  # One-hot encode

        # Split the dataset into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

        # Reshape data for CNN (adding a channel dimension)
        X_train = np.expand_dims(X_train, axis=-1)
        X_test = np.expand_dims(X_test, axis=-1)

        return X_train, X_test, y_train, y_test

    def train_model(self, data_frame, batch_size=32, epochs=20, validation_split=0.2):
        X_train, X_test, y_train, y_test = self.preprocess_data(data_frame)

        # Train the model
        history = self.model.fit(
            X_train, y_train,
            batch_size=batch_size,
            epochs=epochs,
            validation_split=validation_split
        )

        return X_test, y_test, history

    def evaluate_model(self, X_test, y_test):
        y_pred,loss, accuracy = self.model.evaluate(X_test, y_test, verbose=0)
        print(f"Test loss: {loss:.4f}")
        print(f"Test accuracy: {accuracy:.4f}")
        return y_pred,loss, accuracy
